0 training losses:  0.00652129715308547 0.002103644234011881 0.0021036442485637963 0.0021036441830801778 0.00021036442285549128
0 training losses:  0.004284238442778587 0.001382012189424131 0.0013820121785101946 0.0013820122003380675 0.00013820122103425092
0 training losses:  18.233400344848633 5.88174144923687 5.8817414455115795 5.881741506978869 0.5881741582415998
0 training losses:  0.06503105163574219 0.020977760723326355 0.020977760606911033 0.020977760723326355 0.0020977761305402964
0 training losses:  0.0036270294804126024 0.0011700094823936524 0.0011700095315063663 0.0011700095287778822 0.00011700095322453308
0 training losses:  0.0028740500565618277 0.0009271128474210855 0.0009271128401451278 0.0009271128401451278 9.271128692489583e-05
0 training losses:  0.0019031123956665397 0.0006139071506368055 0.0006139071444977162 0.0006139071629149839 6.139071510347094e-05
0 training losses:  0.0019298138795420527 0.0006225205906957854 0.0006225205788723542 0.0006225205870578066 6.225205885357354e-05
0 training losses:  0.001394636114127934 0.0004498825306313847 0.0004498825329051215 0.000449882515738409 4.498825334309231e-05
0 training losses:  0.0017998276744037867 0.0005805896066704008 0.0005805896054198456 0.0005805895879120726 5.80589610663651e-05
0 training losses:  0.0014890744350850582 0.0004803465651548322 0.0004803465793656869 0.0004803465819804842 4.80346588744851e-05
0 training losses:  0.0020482768304646015 0.0006607344870417364 0.0006607344787425973 0.0006607345035263279 6.607345022757727e-05
0 training losses:  0.0031942359637469053 0.0010303986698545486 0.0010303986404096577 0.0010303986329063264 0.00010303986832127521
0 training losses:  0.007767795119434595 0.0025057402308448218 0.0025057403654500376 0.002505740318156313 0.0002505740334299844
0 training losses:  0.011470149271190166 0.0037000480260758195 0.0037000480442657135 0.0037000479314883705 0.00037000480597271235
0 training losses:  0.007612788118422031 0.0024557380165788345 0.0024557379856560146 0.0024557379774705623 0.0002455738025446408
0 training losses:  0.003043475328013301 0.0009817662114528503 0.0009817662128170923 0.0009817662103159819 9.817662234468116e-05
0 training losses:  0.0024837134405970573 0.0008011978297872702 0.000801197833425249 0.0008011978134163655 8.011978457034274e-05
0 training losses:  0.00436731893569231 0.001408812662702985 0.0014088126990827732 0.001408812684530858 0.00014088127045397414
0 training losses:  0.005602642428129911 0.0018073039464070462 0.001807303968234919 0.001807303968234919 0.00018073040155286435
0 training losses:  0.0060535334050655365 0.0019527528784237802 0.0019527528856997378 0.0019527528929756954 0.00019527529093466
0 training losses:  0.0058980402536690235 0.0019025937072001398 0.0019025937290280126 0.0019025937435799278 0.000190259376722679
0 training losses:  0.0056223818100988865 0.001813671515265014 0.0018136715007130988 0.0018136714861611836 0.0001813671542549855
0 training losses:  0.005274110473692417 0.0017013260221574455 0.0017013260076055303 0.0017013260367093608 0.00017013260639942018
0 training losses:  0.004650725517421961 0.0015002339569036849 0.0015002339496277273 0.0015002339423517697 0.0001500233975093579
0 training losses:  0.0035942040849477053 0.001159420789917931 0.0011594207790039945 0.0011594207608141005 0.0001159420789917931
0 training losses:  0.0021593444980680943 0.0006965627781028161 0.0006965628008401836 0.0006965627853787737 6.965627983390732e-05
0 training losses:  0.0021249575074762106 0.0006854700397980196 0.0006854700404801406 0.0006854700245639833 6.854700575331663e-05
0 training losses:  0.004181442316621542 0.001348852287947011 0.001348852287947011 0.0013488522915849899 0.00013488523033799993
0 training losses:  0.007155303377658129 0.0023081623230609694 0.002308162266672298 0.002308162314875517 0.00023081622975951177
0 training losses:  0.008346013724803925 0.0026922621746052755 0.002692262221899 0.002692262243726873 0.0002692262264645251
0 training losses:  0.007399373222142458 0.0023868943953857524 0.002386894379014848 0.0023868943499110173 0.00023868944288096827
0 training losses:  0.006444988772273064 0.0020790288363059517 0.0020790287553609232 0.002079028838124941 0.00020790288624539244
0 training losses:  0.0037254251074045897 0.0012017502449452877 0.0012017501835543953 0.0012017502094749943 0.00012017502257322121
0 training losses:  0.002172044711187482 0.0007006596476912819 0.0007006596197243198 0.0007006596242717933 7.006596533187803e-05
0 training losses:  0.0015337633667513728 0.0004947624057649591 0.0004947623909856702 0.0004947624032638487 4.947624053386335e-05
0 training losses:  0.0017686911160126328 0.0005705455880615773 0.0005705455757833988 0.0005705455635052203 5.7054558737945626e-05
0 training losses:  0.002119977492839098 0.0006838636081738514 0.0006838636440988921 0.000683863615449809 6.838636323891478e-05
0 training losses:  0.0020594121888279915 0.0006643265232924023 0.0006643264987360453 0.0006643265010097821 6.643265319894454e-05
0 training losses:  0.0018197160679847002 0.0005870051656984288 0.000587005190027412 0.0005870051998044801 5.870051879242055e-05
0 training losses:  0.0018036243272945285 0.000581814298811878 0.0005818142922180414 0.0005818143004034937 5.818142976465879e-05
0 training losses:  0.0017956122756004333 0.0005792297552034142 0.0005792297454263462 0.0005792297358766518 5.792297608309127e-05
0 training losses:  0.0017002769745886326 0.000548476400808795 0.000548476375570317 0.0005484763883032429 5.484764020025068e-05
0 valid losses:  0.0014951864268368809 0.0004823182056270525 0.00048231819812372123 0.0004823182097197787 4.823182067070775e-05
0 training loss:  0.0017002769745886326 valid loss:  0.0014951864268368809 training acc:  10.671456112726098 %   valid accuracy:  10.073826455662392 %
/cluster/scratch/jiatang/work/NCA/adddata_5l256_dp0.5/mgpu_ppre_t_grad.py:535: RuntimeWarning: invalid value encountered in arccos
  theta[:,:,i]=np.arccos(0.5*(t1[:,:,i]+t2[:,:,i]+t3[:,:,i]-1))
50 training losses:  0.0003136585291940719 0.0001011801678600932 0.00010118016945170893 0.00010118016859905765 1.0118017051752304e-05
50 training losses:  0.0003073913976550102 9.915851626374206e-05 9.91585142742224e-05 9.915851481423488e-05 9.91585160647901e-06
50 training losses:  0.00031617708737030625 0.00010199260165677515 0.0001019925981893266 0.00010199259816090489 1.0199260135124177e-05
50 training losses:  0.00030669596162624657 9.89341759520812e-05 9.893417526996018e-05 9.893417612261146e-05 9.893417853845676e-06
50 training losses:  0.000320631661452353 0.00010342955383180197 0.00010342955727082881 0.00010342955775399787 1.0342955842901347e-05
50 training losses:  0.00030540089937858284 9.851640905367276e-05 9.851641192426541e-05 9.851640834313002e-05 9.851641358693541e-06
50 training losses:  0.00036720052594318986 0.00011845177124314432 0.00011845176939573321 0.00011845177155578313 1.1845177212421731e-05
50 training losses:  0.0003440163272898644 0.00011097301418772076 0.00011097301424456418 0.00011097301273821358 1.1097301458207198e-05
50 training losses:  0.0003352699859533459 0.00010815161550681296 0.00010815161448363142 0.0001081516138015104 1.0815161619603941e-05
50 training losses:  0.0003349852922838181 0.00010805977018435442 0.00010805977055383664 0.00010805977362338126 1.0805977323613547e-05
50 training losses:  0.0003318779054097831 0.00010705738222327454 0.00010705738111482788 0.00010705738182537061 1.070573839001554e-05
50 training losses:  0.0003056636778637767 9.860117884841202e-05 9.860118186111322e-05 9.860118160531783e-05 9.860118360904835e-06
50 training losses:  0.00038560101529583335 0.0001243874336580575 0.00012438743627285476 0.00012438743272014108 1.2438743485887471e-05
50 training losses:  0.00039381597889587283 0.00012703741441555394 0.00012703741688824266 0.00012703741231234744 1.2703741651520772e-05
50 training losses:  0.00031873281113803387 0.00010281704214776255 0.00010281704308567896 0.00010281704359726973 1.028170455619204e-05
50 training losses:  0.0003252898168284446 0.00010493220071339238 0.00010493220386820212 0.00010493220426610606 1.0493220486296195e-05
50 training losses:  0.00030865613371133804 9.956649321907207e-05 9.956649165587805e-05 9.9566494498049e-05 9.95664959546616e-06
50 training losses:  0.00034390203654766083 0.00011093613676393943 0.00011093613665025259 0.00011093613341017772 1.1093613565549276e-05
50 training losses:  0.0003370546910446137 0.00010872732121924855 0.00010872732502775762 0.00010872732241296035 1.0872732541855612e-05
50 training losses:  0.0003493280673865229 0.00011268647295992196 0.00011268647165252332 0.00011268647222095751 1.1268647348572358e-05
50 training losses:  0.00032708889921195805 0.00010551254158031043 0.00010551254521828923 0.00010551254285928735 1.0551254462143334e-05
50 training losses:  0.00040593728772364557 0.00013094751938069749 0.0001309475151742845 0.000130947522166025 1.3094752031150847e-05
50 training losses:  0.0003839767014142126 0.00012386345187564984 0.00012386345005666044 0.00012386344911874403 1.2386345275672284e-05
50 training losses:  0.00034612638410180807 0.00011165365964416196 0.00011165365879151068 0.00011165366026943957 1.1165366068155436e-05
50 training losses:  0.0003941225295420736 0.00012713630383132113 0.0001271363031492001 0.00012713630269445275 1.2713630617611216e-05
50 training losses:  0.00034281646367162466 0.00011058595293889084 0.00011058595151780537 0.00011058595356416845 1.1058595305257768e-05
50 training losses:  0.0004456983006093651 0.00014377363169160162 0.00014377362992945564 0.00014377363035578128 1.437736334253259e-05
50 training losses:  0.0004262335423845798 0.0001374946947407807 0.00013749468888590854 0.0001374946951102629 1.374946959131762e-05
50 training losses:  0.00033661973429843783 0.00010858701510585433 0.00010858701233473766 0.00010858701813276639 1.0858701608995602e-05
50 training losses:  0.00037055660504847765 0.00011953439658896059 0.00011953439417311529 0.00011953439627632179 1.195343957860473e-05
50 training losses:  0.0003687516145873815 0.00011895214407786625 0.00011895214620949446 0.00011895214771584506 1.1895214655055497e-05
50 training losses:  0.0003586300299502909 0.00011568710868914422 0.00011568710334586285 0.00011568710576170815 1.156871092788947e-05
50 training losses:  0.0003452787350397557 0.00011138025513446337 0.00011138025195123191 0.00011138024882484387 1.1138025355350578e-05
50 training losses:  0.0003106402582488954 0.00010020653320452766 0.00010020653348874475 0.00010020653417086578 1.0020653661513279e-05
50 training losses:  0.00030726820114068687 9.911878112234263e-05 9.91187804402216e-05 9.911877793911117e-05 9.911878148471942e-06
50 training losses:  0.0003629497659858316 0.00011708056166526148 0.00011708056126735755 0.00011708056220527396 1.1708056341319661e-05
50 training losses:  0.0003214601310901344 0.00010369681965016753 0.00010369681731958735 0.00010369681695010513 1.036968216183709e-05
50 training losses:  0.00033822061959654093 0.00010910341046610483 0.00010910340972714039 0.00010910341347880603 1.0910341224246167e-05
50 training losses:  0.0003584115474950522 0.00011561664280179684 0.0001156166366627076 0.00011561663683323786 1.1561664258863402e-05
50 training losses:  0.0003284837875980884 0.00010596251470929019 0.00010596251439665139 0.0001059625147377119 1.0596251446060023e-05
50 training losses:  0.00033469966729171574 0.0001079676108872718 0.00010796761372944275 0.00010796761205256189 1.0796761486631112e-05
50 training losses:  0.00031312351347878575 0.00010100759334363829 0.00010100759635633949 0.00010100759504894086 1.010075966689783e-05
50 training losses:  0.0003315401845611632 0.00010694843834357926 0.00010694844075942456 0.0001069484432889567 1.0694844291947447e-05
50 valid losses:  0.00026862143226935586 8.665207523961271e-05 8.665207357694271e-05 8.665207329272562e-05 8.665207329450197e-06
50 training loss:  0.0003315401845611632 valid loss:  0.00026862143226935586 training acc:  7.54241864502584 %   valid accuracy:  8.629536424946581 %
EarlyStopping counter: 1 out of 70
100 training losses:  0.00028898700838908553 9.322161810132457e-05 9.322161923819294e-05 9.322161838554166e-05 9.32216206805947e-06
100 training losses:  0.0002811061276588589 9.067941090279419e-05 9.06794088280094e-05 9.067940808904495e-05 9.067941292073556e-06
100 training losses:  0.0002840427041519433 9.162668541762287e-05 9.162668533235774e-05 9.162668561657483e-05 9.162668781925731e-06
100 training losses:  0.00027663528453558683 8.92371930376612e-05 8.92371927250224e-05 8.923719013864684e-05 8.92371939187342e-06
100 training losses:  0.000268848380073905 8.672528494457765e-05 8.672528608144603e-05 8.67252875025315e-05 8.672528782227573e-06
100 training losses:  0.00028451773687265813 9.177991393016782e-05 9.177991147168996e-05 9.177991377384842e-05 9.177991325159951e-06
100 training losses:  0.00027557366411201656 8.88947312489563e-05 8.889473050999186e-05 8.889473195949904e-05 8.889473388506985e-06
100 training losses:  0.00029382226057350636 9.478137019414135e-05 9.478136951202032e-05 9.478137016571964e-05 9.478137183549507e-06
100 training losses:  0.00028880106401629746 9.316163937000965e-05 9.31616359025611e-05 9.316163766470709e-05 9.31616402155555e-06
100 training losses:  0.000287141214357689 9.262620810090993e-05 9.26262092093566e-05 9.262620591243831e-05 9.262621098571344e-06
100 training losses:  0.0002883603156078607 9.301944984940747e-05 9.301945081574559e-05 9.301944875517165e-05 9.301945057771377e-06
100 training losses:  0.00028119763010181487 9.070891422879868e-05 9.070891709939133e-05 9.070891326246056e-05 9.07089158985741e-06
100 training losses:  0.00027798337396234274 8.967204522036809e-05 8.967204445298194e-05 8.967204337295698e-05 8.967204507825954e-06
100 training losses:  0.00028350268257781863 9.145248100139725e-05 9.145248219510904e-05 9.145248282038665e-05 9.145248453634736e-06
100 training losses:  0.00029337426531128585 9.463686035360297e-05 9.463686384947323e-05 9.46368625704963e-05 9.4636862648656e-06
100 training losses:  0.00028883476625196636 9.317250720641823e-05 9.317251038964969e-05 9.317251263496473e-05 9.317251183915687e-06
100 training losses:  0.00027466416941024363 8.86013485796866e-05 8.860134659016694e-05 8.860134499855121e-05 8.860134784072216e-06
100 training losses:  0.00027822208357974887 8.97490720035421e-05 8.974906998560073e-05 8.97490710940474e-05 8.974907256487086e-06
100 training losses:  0.00027895098901353776 8.998416927852304e-05 8.998416961958355e-05 8.998416862482372e-05 8.99841697332704e-06
100 training losses:  0.0002792312589008361 9.007459368604032e-05 9.007459826193553e-05 9.007459550502972e-05 9.007459819798669e-06
100 training losses:  0.0002782153896987438 8.97469002438811e-05 8.974690121021922e-05 8.974690248919615e-05 8.974690199892166e-06
100 training losses:  0.00028969417326152325 9.344973526026479e-05 9.344973994984684e-05 9.344973932456924e-05 9.344973916469712e-06
100 training losses:  0.0002799704670906067 9.03130506060279e-05 9.031305248186072e-05 9.031305197026995e-05 9.031305147289004e-06
100 training losses:  0.0002725861268118024 8.793100397497255e-05 8.793100329285153e-05 8.793100687398692e-05 8.79310052326332e-06
100 training losses:  0.00028417111025191844 9.16681152602905e-05 9.166811611294179e-05 9.166811378236162e-05 9.166811715033418e-06
100 training losses:  0.00028417844441719353 9.167045898550441e-05 9.167045956814945e-05 9.167045664071338e-05 9.167046114200161e-06
100 training losses:  0.00026558508398011327 8.567259183678289e-05 8.5672597009534e-05 8.567259240521707e-05 8.567259442315844e-06
100 training losses:  0.00028116031899116933 9.069688871932158e-05 9.069688951512944e-05 9.069688911722551e-05 9.069689156149252e-06
100 training losses:  0.00027528771897777915 8.880248992682027e-05 8.880249185949651e-05 8.880249208687019e-05 8.880249488640857e-06
100 training losses:  0.00029327181982807815 9.46038239533209e-05 9.46038227596091e-05 9.46038278755168e-05 9.460382614179252e-06
100 training losses:  0.0002853947225958109 9.206281167450925e-05 9.206281447404763e-05 9.206281234241942e-05 9.20628144918112e-06
100 training losses:  0.0002884151181206107 9.303712528208052e-05 9.303712468522463e-05 9.303712465680292e-05 9.30371259499907e-06
100 training losses:  0.0002908461610786617 9.382133504232115e-05 9.382133524127312e-05 9.382133430335671e-05 9.382133729474162e-06
100 training losses:  0.00028072769055143 9.055731860030392e-05 9.055732212459588e-05 9.055732232354785e-05 9.05573221032796e-06
100 training losses:  0.00027487645274959505 8.866983434074882e-05 8.86698344402248e-05 8.866983577604515e-05 8.866983556288233e-06
100 training losses:  0.0002807235287036747 9.05559846273718e-05 9.055598303575607e-05 9.055598610530069e-05 9.055598642504492e-06
100 training losses:  0.0002739525807555765 8.83717951012386e-05 8.837179214538082e-05 8.837179439069587e-05 8.837179521492544e-06
100 training losses:  0.00028070216649211943 9.054909270389544e-05 9.054909489236707e-05 9.05490916807139e-05 9.054909316574822e-06
100 training losses:  0.00027907645562663674 9.002464901186613e-05 9.002464938134835e-05 9.002464932450494e-05 9.002465239049684e-06
100 training losses:  0.00028672011103481054 9.24903637553598e-05 9.249036477854133e-05 9.249036662595245e-05 9.24903678622968e-06
100 training losses:  0.00028231553733348846 9.106953461923695e-05 9.106953231707848e-05 9.106953470450208e-05 9.1069535983479e-06
100 training losses:  0.00028650963213294744 9.242246348151184e-05 9.242246345309013e-05 9.242246164831158e-05 9.242246333585058e-06
100 training losses:  0.0002800184884108603 9.032853793655704e-05 9.032853753865311e-05 9.032853549229003e-05 9.03285388353936e-06
100 valid losses:  0.000249505040500253 8.048549688055573e-05 8.048549634764868e-05 8.048549634054325e-05 8.048549943850958e-06
100 training loss:  0.0002800184884108603 valid loss:  0.000249505040500253 training acc:  10.508140544250645 %   valid accuracy:  10.726328792735039 %
150 training losses:  0.00028339604614302516 9.141808146750918e-05 9.141808254753414e-05 9.14180815243526e-05 9.141808455126466e-06
150 training losses:  0.00027105456683784723 8.743696571400505e-05 8.74369616212789e-05 8.743696500346232e-05 8.743696611190899e-06
150 training losses:  0.0002799719222821295 9.03135150451817e-05 9.031351777366581e-05 9.031351842736512e-05 9.031351835275814e-06
150 training losses:  0.0002842690155375749 9.169968620881264e-05 9.169968360822622e-05 9.169968272715323e-05 9.169968551603347e-06
150 training losses:  0.00027681139181368053 8.929399140811256e-05 8.929398745749495e-05 8.929399024282247e-05 8.92939907970458e-06
150 training losses:  0.00027721477090381086 8.942412861756566e-05 8.942413103341096e-05 8.942413171553198e-05 8.942413217027934e-06
150 training losses:  0.00027951315860264003 9.016554005825128e-05 9.016554250251829e-05 9.016553985929932e-05 9.016554287200051e-06
150 training losses:  0.0002792846062220633 9.009182144836814e-05 9.009182087993395e-05 9.009181852093207e-05 9.00918218782465e-06
150 training losses:  0.0002763430238701403 8.914291493056226e-05 8.914291419159781e-05 8.914291493056226e-05 8.914291658612683e-06
150 training losses:  0.00027851801132783294 8.984452406934906e-05 8.984452361460171e-05 8.98445205734788e-05 8.984452424698475e-06
150 training losses:  0.0002914264623541385 9.400855103081085e-05 9.400855367402983e-05 9.40085502634247e-05 9.400855264019015e-06
150 training losses:  0.00028922269120812416 9.329764145604713e-05 9.329764353083192e-05 9.329764122867346e-05 9.32976420209286e-06
150 training losses:  0.0002720039919950068 8.774322594717887e-05 8.774322648719135e-05 8.774322770932486e-05 8.774322818538849e-06
150 training losses:  0.0002691310946829617 8.681646988861758e-05 8.681646886543604e-05 8.681647068442544e-05 8.68164697109819e-06
150 training losses:  0.00027397857047617435 8.838020113444145e-05 8.838019988388623e-05 8.83802024986835e-05 8.838020224999354e-06
150 training losses:  0.0002791475271806121 9.004760136122059e-05 9.004759829167597e-05 9.004759752428981e-05 9.004760096686937e-06
150 training losses:  0.0002650738169904798 8.550768447435075e-05 8.550768328063896e-05 8.550768484383298e-05 8.550768789916674e-06
150 training losses:  0.0002678668242879212 8.640865391384978e-05 8.640865618758653e-05 8.640865553388721e-05 8.640865775788598e-06
150 training losses:  0.00027447359752841294 8.853986500412248e-05 8.853986699364214e-05 8.85398665957382e-05 8.853986813051051e-06
150 training losses:  0.0002698582538869232 8.705105761919185e-05 8.70510574486616e-05 8.705105457806894e-05 8.705105884132536e-06
150 training losses:  0.0002769295824691653 8.933210867212438e-05 8.933210961004079e-05 8.933211071848746e-05 8.933211123718365e-06
150 training losses:  0.00027344643604010344 8.82085297746471e-05 8.820853227575753e-05 8.820852880830898e-05 8.820853153679309e-06
150 training losses:  0.00027453736402094364 8.856043461946683e-05 8.856043598370889e-05 8.856043439209316e-05 8.856043720584239e-06
150 training losses:  0.00026521613472141325 8.55535829487053e-05 8.555358277817504e-05 8.555358391504342e-05 8.555358530060175e-06
150 training losses:  0.0002710646949708462 8.744021471329688e-05 8.744021548068304e-05 8.744021337747654e-05 8.74402145356612e-06
150 training losses:  0.00027698330814018846 8.934945341820821e-05 8.934945310556941e-05 8.934945245187009e-05 8.934945277871975e-06
150 training losses:  0.00027185672661289573 8.769570513322833e-05 8.76957008131285e-05 8.769570055733311e-05 8.769570303712726e-06
150 training losses:  0.00026615255046635866 8.585565655039318e-05 8.58556526850407e-05 8.58556532818966e-05 8.58556547100875e-06
150 training losses:  0.0002832018071785569 9.135542114790951e-05 9.135542390481532e-05 9.135542489957515e-05 9.135542402560759e-06
150 training losses:  0.0002943622530438006 9.495556088268131e-05 9.49555626448273e-05 9.495556153638063e-05 9.49555649043532e-06
150 training losses:  0.0002942955179605633 9.493402990301547e-05 9.493403106830556e-05 9.493402924931615e-05 9.493403076987761e-06
150 training losses:  0.0002772929728962481 8.944934788246428e-05 8.944934850774189e-05 8.94493491330195e-05 8.944934990040565e-06
150 training losses:  0.0002800393558572978 9.033527334167957e-05 9.033527413748743e-05 9.03352725458717e-05 9.033527483381931e-06
150 training losses:  0.0002693567075766623 8.688926700983757e-05 8.688926629929483e-05 8.688926703825928e-05 8.688926779854e-06
150 training losses:  0.000286245223833248 9.233715843492973e-05 9.233715883283367e-05 9.233716198764341e-05 9.233716200540698e-06
150 training losses:  0.0002877359220292419 9.281804815941541e-05 9.281804622673917e-05 9.281804966576601e-05 9.281804878469302e-06
150 training losses:  0.0002770129940472543 8.935903804285772e-05 8.935904179452336e-05 8.935904185136678e-05 8.935904212137302e-06
150 training losses:  0.0002745427191257477 8.856218028086005e-05 8.856218181563236e-05 8.856218062192056e-05 8.856218066455313e-06
150 training losses:  0.0002735863090492785 8.825364565723248e-05 8.825364415088188e-05 8.825364247400103e-05 8.825364712805595e-06
150 training losses:  0.000282498134765774 9.11284273001911e-05 9.112842701597401e-05 9.112842670333521e-05 9.112842960234957e-06
150 training losses:  0.00027841507107950747 8.981131944096887e-05 8.981132054941554e-05 8.981131978202939e-05 8.98113197322914e-06
150 training losses:  0.0002778730704449117 8.963648696180826e-05 8.963648673443458e-05 8.963648880921937e-05 8.963648916449074e-06
150 training losses:  0.0002752091677393764 8.87771442421581e-05 8.877714762434152e-05 8.877714330424169e-05 8.877714737565157e-06
150 valid losses:  0.000238665141466754 7.698875620576473e-05 7.698875658235238e-05 7.698875509021263e-05 7.698875648998182e-06
150 training loss:  0.0002752091677393764 valid loss:  0.000238665141466754 training acc:  14.956117772932815 %   valid accuracy:  14.111536792200853 %
200 training losses:  0.0002742982469499111 8.84833131067353e-05 8.848331370359119e-05 8.84833134193741e-05 8.84833139380703e-06
200 training losses:  0.0002920483238995075 9.420914707902739e-05 9.42091474200879e-05 9.420914793167867e-05 9.420914905078348e-06
200 training losses:  0.0002797948836814612 9.025640697757353e-05 9.02564073328449e-05 9.025640844129157e-05 9.025640931525913e-06
200 training losses:  0.00029570196056738496 9.538771888628617e-05 9.538771547568103e-05 9.53877159872718e-05 9.538771823969228e-06
200 training losses:  0.0002714390866458416 8.756100550044721e-05 8.756099998663558e-05 8.75610039656749e-05 8.756100548623635e-06
200 training losses:  0.00027619919274002314 8.909651802468943e-05 8.909651918997952e-05 8.909651700150789e-05 8.909651846522593e-06
200 training losses:  0.0002883100532926619 9.300325035610513e-05 9.300324674654803e-05 9.30032478834164e-05 9.300325046979196e-06
200 training losses:  0.00029649672796949744 9.564410430584758e-05 9.564410223106279e-05 9.564410328266604e-05 9.564410692775027e-06
200 training losses:  0.00027919799322262406 9.006387358567736e-05 9.006387114141035e-05 9.006387256249582e-05 9.006387347909595e-06
200 training losses:  0.0002911446790676564 9.391763023813837e-05 9.391763160238042e-05 9.391763177291068e-05 9.391763359900551e-06
200 training losses:  0.0002927342429757118 9.443039661505281e-05 9.44303956487147e-05 9.44303980929817e-05 9.44303971550653e-06
200 training losses:  0.00028508176910690963 9.196185854420946e-05 9.196185808946211e-05 9.196186147164553e-05 9.19618612016393e-06
200 training losses:  0.0002791399019770324 9.004513361787758e-05 9.004513179888818e-05 9.004513321997365e-05 9.004513422894433e-06
200 training losses:  0.0002674149291124195 8.626288479263167e-05 8.626288570212637e-05 8.626288192203901e-05 8.626288643398539e-06
200 training losses:  0.00026834156597033143 8.656177914190266e-05 8.656177976718027e-05 8.656177669763565e-05 8.656177989507796e-06
200 training losses:  0.00029233304667286575 9.430098435814216e-05 9.430098319285207e-05 9.430098575080592e-05 9.430098685925259e-06
200 training losses:  0.0002773654705379158 8.947273991566362e-05 8.947273829562619e-05 8.947273897774721e-05 8.947274064752264e-06
200 training losses:  0.0002824447874445468 9.111121940463818e-05 9.111121804039612e-05 9.111121772775732e-05 9.111122007965378e-06
200 training losses:  0.0002802833332680166 9.041398482168006e-05 9.041398521958399e-05 9.041398152476177e-05 9.041398634224151e-06
200 training losses:  0.0002785428077913821 8.985251935200722e-05 8.985252105730979e-05 8.985252196680449e-05 8.985252218707274e-06
200 training losses:  0.0002841881650965661 9.167359189632407e-05 9.167359155526356e-05 9.167358902573142e-05 9.167359175776824e-06
200 training losses:  0.00027888655313290656 8.996340508815592e-05 8.996340429234806e-05 8.996340787348345e-05 8.996340600475605e-06
200 training losses:  0.0002723262587096542 8.784718951915238e-05 8.784718986021289e-05 8.784719051391221e-05 8.784719188525969e-06
200 training losses:  0.00027704521198756993 8.936941134152221e-05 8.936941355841554e-05 8.936941458159708e-05 8.936941547688093e-06
200 training losses:  0.0002912738127633929 9.39592969473324e-05 9.395929919264745e-05 9.395929868105668e-05 9.395929886579779e-06
200 training losses:  0.00028274295618757606 9.120739071022399e-05 9.120738778278792e-05 9.120739272816536e-05 9.12073929981716e-06
200 training losses:  0.00027475159731693566 8.862953424682019e-05 8.862953089305847e-05 8.862953637844839e-05 8.862953485788694e-06
200 training losses:  0.000274175574304536 8.844373309102593e-05 8.844372950989055e-05 8.84437320678444e-05 8.844373454053311e-06
200 training losses:  0.0002753190929070115 8.881260845328143e-05 8.881260873749852e-05 8.881260998805374e-05 8.881260985305062e-06
200 training losses:  0.00028339726850390434 9.14184618636682e-05 9.141846538796017e-05 9.141846442162205e-05 9.141846629034944e-06
200 training losses:  0.00028999848291277885 9.354790245197364e-05 9.354790003612834e-05 9.354789796134355e-05 9.354790009297176e-06
200 training losses:  0.0002863127156160772 9.235893040226983e-05 9.235892929382317e-05 9.23589333297059e-05 9.235893337233847e-06
200 training losses:  0.0002788271813187748 8.994424499064735e-05 8.994424490538222e-05 8.99442466391065e-05 8.994424732122752e-06
200 training losses:  0.0002795384789351374 9.01737121523638e-05 9.017370740593833e-05 9.017370936703628e-05 9.017371187525214e-06
200 training losses:  0.00027811803738586605 8.971551892500429e-05 8.971551770287078e-05 8.971552000502925e-05 8.971552006187267e-06
200 training losses:  0.00027503850287757814 8.872210801769143e-05 8.8722107960848e-05 8.872210830190852e-05 8.872210848664963e-06
200 training losses:  0.0002666534564923495 8.601723791912264e-05 8.601723669698913e-05 8.601723610013323e-05 8.601723660461857e-06
200 training losses:  0.0002740382042247802 8.839941642690974e-05 8.839941676797025e-05 8.839941537530649e-05 8.839941838090226e-06
200 training losses:  0.0002737994655035436 8.832240547462789e-05 8.83224049061937e-05 8.83224076346778e-05 8.83224067749211e-06
200 training losses:  0.0002782686788123101 8.976410356353881e-05 8.976410464356377e-05 8.97641035351171e-05 8.976410409644586e-06
200 training losses:  0.0002848357253242284 9.188248614577788e-05 9.188248981217839e-05 9.188248853320147e-05 9.188248967006984e-06
200 training losses:  0.00027614980353973806 8.908057338885556e-05 8.908056963718991e-05 8.908057486678445e-05 8.908057431256111e-06
200 training losses:  0.0002856109058484435 9.21325533909112e-05 9.213255111717444e-05 9.21325510034876e-05 9.213255346196547e-06
200 valid losses:  0.0002491142345206754 8.035942501294357e-05 8.035942980200161e-05 8.035942818196418e-05 8.035942913764416e-06
200 training loss:  0.0002856109058484435 valid loss:  0.0002491142345206754 training acc:  18.83811773255814 %   valid accuracy:  15.399326422275642 %
250 training losses:  0.00029881278169341385 9.639120750648544e-05 9.639120654014732e-05 9.639120480642305e-05 9.639120893467634e-06
250 training losses:  0.00029730488313362 9.590480490828668e-05 9.590480749466224e-05 9.59048025777065e-05 9.590480757992736e-06
250 training losses:  0.0002840724482666701 9.163627728980828e-05 9.163628072883512e-05 9.163628132569102e-05 9.16362797909187e-06
250 training losses:  0.0002860579697880894 9.22767555948667e-05 9.227675684542191e-05 9.22767555948667e-05 9.227675853651363e-06
250 training losses:  0.0002803310053423047 9.042935590741763e-05 9.042935886327541e-05 9.042935505476635e-05 9.04293597159267e-06
250 training losses:  0.0002915067016147077 9.40344192486009e-05 9.403441723065953e-05 9.403441879385355e-05 9.403441868727214e-06
250 training losses:  0.00029822616488672793 9.620197434401234e-05 9.620197405979525e-05 9.620197539561559e-05 9.620197566562183e-06
250 training losses:  0.00028347416082397103 9.144328618049258e-05 9.144328663523993e-05 9.14432829404177e-05 9.144328707577642e-06
250 training losses:  0.0002737393951974809 8.830302869000661e-05 8.83030304521526e-05 8.830302846263294e-05 8.830302999029982e-06
250 training losses:  0.00028913424466736615 9.326910910090191e-05 9.326910623030926e-05 9.326910600293559e-05 9.326910799245525e-06
250 training losses:  0.0002859646629076451 9.224665467399973e-05 9.224665529927734e-05 9.224665654983255e-05 9.224665820539713e-06
250 training losses:  0.00027803887496702373 8.968995899749643e-05 8.9689956496386e-05 8.968995854274908e-05 8.968995953040348e-06
250 training losses:  0.00027034064987674356 8.720666460249049e-05 8.720666517092468e-05 8.720666443196023e-05 8.72066657464643e-06
250 training losses:  0.00027232212596572936 8.784582342968861e-05 8.784582587395562e-05 8.784582360021886e-05 8.784582579579592e-06
250 training losses:  0.0002909051545429975 9.384036073356583e-05 9.384035726611728e-05 9.384036161463882e-05 9.384036204096446e-06
250 training losses:  0.00028694194043055177 9.256191913209477e-05 9.256191864892571e-05 9.25619207237105e-05 9.256191990658635e-06
250 training losses:  0.0002673299459274858 8.62354749244787e-05 8.62354734465498e-05 8.623547512343066e-05 8.623547500974382e-06
250 training losses:  0.0002723732904996723 8.78623542917012e-05 8.786234934632375e-05 8.786235139268683e-05 8.78623543698609e-06
250 training losses:  0.0002877869992516935 9.283450916086622e-05 9.283450719976827e-05 9.283450754082878e-05 9.283450808084126e-06
250 training losses:  0.00027538847643882036 8.883499509693138e-05 8.88350002696825e-05 8.883499779699378e-05 8.883499944545292e-06
250 training losses:  0.0002756654575932771 8.8924341270058e-05 8.892434075846722e-05 8.892433814366996e-05 8.892434262719462e-06
250 training losses:  0.0002720364718697965 8.775369866498295e-05 8.775369948921252e-05 8.775369954605594e-05 8.7753700910298e-06
250 training losses:  0.00027586836949922144 8.898978691718185e-05 8.898978754245945e-05 8.89897904130521e-05 8.898979039884125e-06
250 training losses:  0.00026824622182175517 8.653102807443247e-05 8.653102949551794e-05 8.65310272502029e-05 8.65310307318623e-06
250 training losses:  0.00027773523470386863 8.959201011293771e-05 8.959201565517105e-05 8.959201534253225e-05 8.959201657887661e-06
250 training losses:  0.00027972235693596303 9.023302163768676e-05 9.023302200716898e-05 9.023302141031309e-05 9.023302386168552e-06
250 training losses:  0.00028561262297444046 9.213311099642851e-05 9.21331088648003e-05 9.213310991640355e-05 9.213310956823761e-06
250 training losses:  0.00028018929879181087 9.038364169100532e-05 9.038364441948943e-05 9.03836437373684e-05 9.038364467528481e-06
250 training losses:  0.00027536749257706106 8.88282230562254e-05 8.882822294253856e-05 8.88282245909977e-05 8.882822537970014e-06
250 training losses:  0.0002872214245144278 9.265206946906801e-05 9.265207057751468e-05 9.26520718564916e-05 9.265207133068998e-06
250 training losses:  0.0002892703632824123 9.331302021564625e-05 9.331301993142915e-05 9.33130182545483e-05 9.331302081250215e-06
250 training losses:  0.00028887391090393066 9.318512852019012e-05 9.318513048128807e-05 9.318513323819388e-05 9.318513210843093e-06
250 training losses:  0.000285028392681852 9.194462833761463e-05 9.19446282523495e-05 9.19446288492054e-05 9.19446307179328e-06
250 training losses:  0.0002806877309922129 9.05444160252955e-05 9.054441613898234e-05 9.054441437683636e-05 9.054441726163986e-06
250 training losses:  0.00027915736427530646 9.005076788071165e-05 9.005076478274532e-05 9.005076705648207e-05 9.005076897494746e-06
250 training losses:  0.00027781599783338606 8.961805730223205e-05 8.961805610852025e-05 8.961805650642418e-05 8.961805725959948e-06
250 training losses:  0.0002801035298034549 9.035597594220235e-05 9.035597486217739e-05 9.035597742013124e-05 9.0355977100387e-06
250 training losses:  0.00028319191187620163 9.135222467193671e-05 9.135222632039586e-05 9.135222700251688e-05 9.135222683198663e-06
250 training losses:  0.0002846980351023376 9.183806992041355e-05 9.18380673624597e-05 9.183807071622141e-05 9.18380698067267e-06
250 training losses:  0.0002847195719368756 9.184502806647288e-05 9.18450239169033e-05 9.184502445691578e-05 9.18450280451566e-06
250 training losses:  0.0002932213537860662 9.45875393085771e-05 9.458753805802189e-05 9.458753635271933e-05 9.458753918778484e-06
250 training losses:  0.000290600408334285 9.374206507573035e-05 9.374206726420198e-05 9.374206453571787e-05 9.374206761947335e-06
250 training losses:  0.00030024340958334506 9.685271496095993e-05 9.685271075454693e-05 9.68527136535613e-05 9.685271395554196e-06
250 valid losses:  0.00025191417307723896 8.126263844587811e-05 8.126263656293986e-05 8.126263562502345e-05 8.12626385204851e-06
250 training loss:  0.00030024340958334506 valid loss:  0.00025191417307723896 training acc:  22.598690851098194 %   valid accuracy:  16.725093482905983 %
300 training losses:  0.00028127594850957394 9.073417425042862e-05 9.073416993032879e-05 9.073417461991085e-05 9.073417380989213e-06
300 training losses:  0.00028247589943930507 9.112125974297669e-05 9.112126207355686e-05 9.112126286936473e-05 9.112126228671968e-06
300 training losses:  0.0002850876480806619 9.196375384590283e-05 9.19637540732765e-05 9.196375452802386e-05 9.196375440723159e-06
300 training losses:  0.0002996582770720124 9.666396721286219e-05 9.666396823604373e-05 9.666396820762202e-05 9.666396923790899e-06
300 training losses:  0.0002780846261885017 8.970471279212688e-05 8.970471381530842e-05 8.970471668590108e-05 8.970471508717992e-06
300 training losses:  0.00028260372346267104 9.116249310636704e-05 9.116249412954858e-05 9.116249515273012e-05 9.116249579221858e-06
300 training losses:  0.00028972691507078707 9.346030486767631e-05 9.346030367396452e-05 9.346030356027768e-05 9.346030438450725e-06
300 training losses:  0.0003100752946920693 0.00010002427029576211 0.00010002427495692245 0.00010002427103472655 1.0002427401900604e-05
300 training losses:  0.0003135558217763901 0.00010114704099351002 0.00010114703940189429 0.00010114703985664164 1.0114704252828233e-05
300 training losses:  0.0003035977715626359 9.793476380082211e-05 9.79347640850392e-05 9.793476561981151e-05 9.793476699826442e-06
300 training losses:  0.0002849969605449587 9.193450409838988e-05 9.193450352995569e-05 9.193450443945039e-05 9.193450626554522e-06
300 training losses:  0.0002905087894760072 9.371252352252668e-05 9.371252554046805e-05 9.371252880896463e-05 9.371252680523412e-06
300 training losses:  0.0002805785625241697 9.050921431708048e-05 9.0509212895995e-05 9.050921204334372e-05 9.050921413233937e-06
300 training losses:  0.000289269897621125 9.331287282066114e-05 9.331287606073602e-05 9.33128729911914e-05 9.331287515124131e-06
300 training losses:  0.00029995289514772594 9.675899858052617e-05 9.675899872263471e-05 9.675899951844258e-05 9.675899974581625e-06
300 training losses:  0.00033384416019544005 0.00010769167434432347 0.0001076916774422898 0.00010769167579383065 1.0769167687385561e-05
300 training losses:  0.000284749228740111 9.185457994931312e-05 9.185458156935056e-05 9.185458091565124e-05 9.185458182514594e-06
300 training losses:  0.0002863130357582122 9.235904326487798e-05 9.235904303750431e-05 9.235904485649371e-05 9.235904450122234e-06
300 training losses:  0.0003037000715266913 9.796776362236415e-05 9.796776521397987e-05 9.796776691928244e-05 9.79677681556268e-06
300 training losses:  0.0002949479385279119 9.514449095604505e-05 9.51444908139365e-05 9.514449149605753e-05 9.514449324399266e-06
300 training losses:  0.00030136879649944603 9.721575509047398e-05 9.721575116827808e-05 9.721575557364304e-05 9.721575445098551e-06
300 training losses:  0.0002912119380198419 9.393934294621431e-05 9.393934249146696e-05 9.393934357149192e-05 9.39393453336379e-06
300 training losses:  0.00029259073198772967 9.438411086648557e-05 9.438410995699087e-05 9.438411103701583e-05 9.438411076700959e-06
300 training losses:  0.00027774021145887673 8.959361369420549e-05 8.959361412053113e-05 8.959361468896532e-05 8.959361508686925e-06
300 training losses:  0.00027490450884215534 8.86788813829753e-05 8.867887953556419e-05 8.867888229247001e-05 8.867888322328099e-06
300 training losses:  0.00028471503173932433 9.184355928937293e-05 9.18435621883873e-05 9.184356167679653e-05 9.18435619823299e-06
300 training losses:  0.0002818680659402162 9.092517399267308e-05 9.092518075703993e-05 9.092517728959137e-05 9.092517920805676e-06
300 training losses:  0.00029206444742158055 9.421431801115432e-05 9.42143194606615e-05 9.421432076806013e-05 9.42143202919965e-06
300 training losses:  0.0002975876268465072 9.599600750220816e-05 9.59960061095444e-05 9.59960040063379e-05 9.599600733878333e-06
300 training losses:  0.0002874258207157254 9.271801530985613e-05 9.271801803834023e-05 9.271801519616929e-05 9.271801719279438e-06
300 training losses:  0.0002930660848505795 9.453744735310465e-05 9.453744513621132e-05 9.453744343090875e-05 9.45374463512394e-06
300 training losses:  0.0002890843607019633 9.325301206786207e-05 9.325300899831745e-05 9.325301158469301e-05 9.325301256524199e-06
300 training losses:  0.000282654189504683 9.117876854247697e-05 9.117877098674398e-05 9.117876948039338e-05 9.117877205255809e-06
300 training losses:  0.0002864773850888014 9.24120657828098e-05 9.241206521437562e-05 9.241206760179921e-05 9.241206747390152e-06
300 training losses:  0.00028204856789670885 9.098341274693666e-05 9.09834143669741e-05 9.098341607227667e-05 9.09834167828194e-06
300 training losses:  0.0003025962505489588 9.761169053490448e-05 9.761168945487952e-05 9.761169422972671e-05 9.761169295074978e-06
300 training losses:  0.0002804007672239095 9.045185856848548e-05 9.045185737477368e-05 9.045185666423095e-05 9.045185830558466e-06
300 training losses:  0.0002847626165021211 9.185891877905306e-05 9.185891855167938e-05 9.185891872220964e-05 9.185892075436186e-06
300 training losses:  0.00028888261294923723 9.318795389390289e-05 9.318794877799519e-05 9.318794786850049e-05 9.31879522880763e-06
300 training losses:  0.0002934953081421554 9.467590223266598e-05 9.467590467693299e-05 9.467590456324615e-05 9.467590441403217e-06
300 training losses:  0.000290375086478889 9.366938090238364e-05 9.366938135713099e-05 9.366938002131064e-05 9.366938170884964e-06
300 training losses:  0.00028389354702085257 9.157855697594641e-05 9.157855470220966e-05 9.157855765806744e-05 9.157855672015103e-06
300 training losses:  0.0002833300386555493 9.139680406633488e-05 9.139680219050206e-05 9.139680378211779e-05 9.139680450687138e-06
300 valid losses:  0.0002726702436461892 8.795814280659897e-05 8.795814298423466e-05 8.795814282080983e-05 8.795814424367165e-06
300 training loss:  0.0002833300386555493 valid loss:  0.0002726702436461892 training acc:  28.823153867894053 %   valid accuracy:  21.946468516292732 %
350 training losses:  0.00029128065216355026 9.396150500151634e-05 9.396150602469788e-05 9.39615063657584e-05 9.396150908003165e-06
350 training losses:  0.0002841910463757813 9.167452753899852e-05 9.167452557790057e-05 9.1674524753671e-05 9.167452631686501e-06
350 training losses:  0.000289931456791237 9.35262759469424e-05 9.352627446901352e-05 9.3526275009026e-05 9.352627749592557e-06
350 training losses:  0.00029585426091216505 9.543685615653885e-05 9.543685746393749e-05 9.543685621338227e-05 9.543685688839787e-06
350 training losses:  0.00028831505915150046 9.30048433929187e-05 9.300484663299358e-05 9.300484464347392e-05 9.300484542507093e-06
350 training losses:  0.0002959769044537097 9.547642451934735e-05 9.547641852236666e-05 9.547642343932239e-05 9.547642516594124e-06
350 training losses:  0.00029235632973723114 9.430850229819043e-05 9.430850207081676e-05 9.430849812019915e-05 9.430850397507129e-06
350 training losses:  0.00030114359105937183 9.714309089758899e-05 9.714309186392711e-05 9.714309209130079e-05 9.71430940666096e-06
350 training losses:  0.0002851192548405379 9.197395161208988e-05 9.197394905413603e-05 9.197394894044919e-05 9.197395215210236e-06
350 training losses:  0.0002958476834464818 9.543474581619193e-05 9.543474342876834e-05 9.543474411088937e-05 9.543474657647266e-06
350 training losses:  0.00028410879895091057 9.164799692484848e-05 9.164799553218472e-05 9.164799755012609e-05 9.164799575245297e-06
350 training losses:  0.00028685297002084553 9.253322212998683e-05 9.253322133417896e-05 9.253322212998683e-05 9.253322296842725e-06
350 training losses:  0.0002843753609340638 9.17339739316958e-05 9.173397114636828e-05 9.173397324957477e-05 9.173397568673636e-06
350 training losses:  0.0002865474671125412 9.243466951147639e-05 9.243466965358493e-05 9.243467144415263e-05 9.243467072650446e-06
350 training losses:  0.0002819650690071285 9.095647527601614e-05 9.095647652657135e-05 9.09564763560411e-05 9.095647797607853e-06
350 training losses:  0.00029634349630214274 9.55946638896421e-05 9.559466184327903e-05 9.559466684549989e-05 9.559466462860655e-06
350 training losses:  0.00029809761326760054 9.616051079319732e-05 9.616051488592348e-05 9.616051107741441e-05 9.616051432459471e-06
350 training losses:  0.000306600151816383 9.890325142691836e-05 9.890325512174059e-05 9.890325404171563e-05 9.890325575412362e-06
350 training losses:  0.0002965665771625936 9.56666333991052e-05 9.566662782845015e-05 9.566663112536844e-05 9.56666325180322e-06
350 training losses:  0.00029704562621191144 9.582117058926087e-05 9.58211694523925e-05 9.582116547335318e-05 9.582117101558651e-06
350 training losses:  0.0002948355977423489 9.510826706105036e-05 9.51082635936018e-05 9.510826583891685e-05 9.510826714631548e-06
350 training losses:  0.00029027974233031273 9.363862733380302e-05 9.363862452005378e-05 9.363862693589908e-05 9.36386261329858e-06
350 training losses:  0.0002845069393515587 9.17764319581238e-05 9.177642851909695e-05 9.177643079283371e-05 9.17764321428649e-06
350 training losses:  0.00027912287623621523 9.003963936038417e-05 9.003963452869357e-05 9.003963816667238e-05 9.003963910458879e-06
350 training losses:  0.00028490947443060577 9.190627457655864e-05 9.190627753241642e-05 9.190627366706394e-05 9.19062753723665e-06
350 training losses:  0.00029687187634408474 9.576512456987984e-05 9.576512320563779e-05 9.576512491094036e-05 9.576512741915622e-06
350 training losses:  0.000288068171357736 9.292521534121079e-05 9.292521403381215e-05 9.292521681913968e-05 9.292521628623263e-06
350 training losses:  0.0002825682167895138 9.115102676560127e-05 9.115102665191444e-05 9.115102517398554e-05 9.11510271350835e-06
350 training losses:  0.00028040396864525974 9.045290124731764e-05 9.04528990304243e-05 9.045289965570191e-05 9.045290184417354e-06
350 training losses:  0.000298667058814317 9.634421385840142e-05 9.634421056148312e-05 9.634421328996723e-05 9.634421470394727e-06
350 training losses:  0.00030281743966042995 9.768305000079636e-05 9.768305179136405e-05 9.768305028501345e-05 9.76830536991713e-06
350 training losses:  0.0002899447572417557 9.353056032068707e-05 9.353055912697528e-05 9.3530558274324e-05 9.353056064753673e-06
350 training losses:  0.00029286707285791636 9.447323850508837e-05 9.447323924405282e-05 9.447324231359744e-05 9.447324039513205e-06
350 training losses:  0.0002874139463528991 9.271417243894575e-05 9.271417366107926e-05 9.271417593481601e-05 9.271417489742362e-06
350 training losses:  0.0002910981420427561 9.390262698616425e-05 9.390262755459844e-05 9.390262786723724e-05 9.39026304003221e-06
350 training losses:  0.0002892216434702277 9.329730767149158e-05 9.32973074441179e-05 9.329730727358765e-05 9.329730886520338e-06
350 training losses:  0.00027795234927907586 8.966204700300295e-05 8.96620447292662e-05 8.966204370608466e-05 8.966204731564176e-06
350 training losses:  0.0002961316204164177 9.5526322979822e-05 9.552632366194302e-05 9.552632204190559e-05 9.552632333154065e-06
350 training losses:  0.0002898578823078424 9.350254180162665e-05 9.350253912998596e-05 9.350254094897537e-05 9.350254302376015e-06
350 training losses:  0.00028239632956683636 9.109559135822565e-05 9.109559078979146e-05 9.109559039188753e-05 9.109559265141343e-06
350 training losses:  0.0002801581867970526 9.037360797492511e-05 9.037361320451964e-05 9.03736106465658e-05 9.03736127000343e-06
350 training losses:  0.0002845207927748561 9.178089271699719e-05 9.17808942517695e-05 9.178088839689735e-05 9.178089335648565e-06
350 training losses:  0.0002919413091149181 9.417463525096537e-05 9.417463519412195e-05 9.41746338298799e-05 9.417463761707268e-06
350 valid losses:  0.0002536943147219972 8.183687484120128e-05 8.183687518226179e-05 8.18368753385812e-05 8.183687468132916e-06
350 training loss:  0.0002919413091149181 valid loss:  0.0002536943147219972 training acc:  39.01909722222222 %   valid accuracy:  29.677796975160255 %
400 training losses:  0.00027982977917417884 9.026765863495712e-05 9.026765755493216e-05 9.026766062447678e-05 9.02676598002472e-06
400 training losses:  0.0002804419491440058 9.0465156887376e-05 9.046515677368916e-05 9.046515739896677e-05 9.04651597721795e-06
400 training losses:  0.0002946142922155559 9.503686277412271e-05 9.503686192147143e-05 9.503685947720442e-05 9.503686385414767e-06
400 training losses:  0.00029843373340554535 9.626895547398817e-05 9.626895530345791e-05 9.626895416658954e-05 9.62689581029963e-06
400 training losses:  0.0002804182004183531 9.045749294500638e-05 9.045749447977869e-05 9.045749260394587e-05 9.045749589375873e-06
400 training losses:  0.0002770804276224226 8.938077755260565e-05 8.938077934317334e-05 8.938077900211283e-05 8.938078114084647e-06
400 training losses:  0.0002822566602844745 9.105054874680718e-05 9.10505427782482e-05 9.10505460751665e-05 9.105054886049402e-06
400 training losses:  0.0002876508515328169 9.279060759581625e-05 9.279060537892292e-05 9.279060552103147e-05 9.279060790845506e-06
400 training losses:  0.0002853968762792647 9.206350713952816e-05 9.206350472368285e-05 9.206350168255995e-05 9.206350579660239e-06
400 training losses:  0.00027516353293322027 8.876243418853846e-05 8.87624385086383e-05 8.876243447275556e-05 8.876243619226898e-06
400 training losses:  0.0002797208435367793 9.023252948736626e-05 9.023252943052285e-05 9.023253267059772e-05 9.023253205953097e-06
400 training losses:  0.0002865925489459187 9.244919471029789e-05 9.244919783668593e-05 9.244919647244387e-05 9.244919709772148e-06
400 training losses:  0.000290182011667639 9.360710629380264e-05 9.360709978523118e-05 9.360710481587375e-05 9.360710592432042e-06
400 training losses:  0.0002750944113358855 8.87401252498421e-05 8.874012928572483e-05 8.874012962678535e-05 8.874012941362253e-06
400 training losses:  0.0002821031375788152 9.100102153070111e-05 9.100102147385769e-05 9.10010239181247e-05 9.100102502657137e-06
400 training losses:  0.00028622045647352934 9.23291810011051e-05 9.232917989265843e-05 9.232917631152304e-05 9.232918078083685e-06
400 training losses:  0.00028066159575246274 9.053599421804392e-05 9.053598640207383e-05 9.053599242747623e-05 9.053599303143756e-06
400 training losses:  0.00027132831746712327 8.752525673116907e-05 8.752525548061385e-05 8.752525724275984e-05 8.7525258791743e-06
400 training losses:  0.00029129584436304867 9.396640018621838e-05 9.396640473369189e-05 9.396640228942488e-05 9.39664042931554e-06
400 training losses:  0.0002970352361444384 9.581781188217064e-05 9.581781301903902e-05 9.58178165717527e-05 9.581781458933847e-06
400 training losses:  0.0002987900224979967 9.63838722896071e-05 9.638387103905188e-05 9.638386885058026e-05 9.638387219013111e-06
400 training losses:  0.0002694562717806548 8.692136532317818e-05 8.692136435684006e-05 8.692136850640964e-05 8.692136855614763e-06
400 training losses:  0.0002759972703643143 8.903138581217718e-05 8.9031383481597e-05 8.90313864942982e-05 8.903138557059265e-06
400 training losses:  0.0002749883569777012 8.870590269793865e-05 8.870590539800105e-05 8.870590340848139e-05 8.870590470166917e-06
400 training losses:  0.0002854159101843834 9.206963872543383e-05 9.206963781593913e-05 9.206964020336272e-05 9.206963976993165e-06
400 training losses:  0.00027861460694111884 8.987567264284735e-05 8.987567355234205e-05 8.987567554186171e-05 8.987567419183051e-06
400 training losses:  0.00028215133352205157 9.10165554159903e-05 9.101655962240329e-05 9.101655894028227e-05 9.101655969345757e-06
400 training losses:  0.0002848237636499107 9.187862323756235e-05 9.187862357862286e-05 9.187862215753739e-05 9.187862534787428e-06
400 training losses:  0.00028403737815096974 9.162494791326026e-05 9.162495123860026e-05 9.162494995962334e-05 9.16249517146639e-06
400 training losses:  0.0002761318173725158 8.907478951414305e-05 8.907478820674442e-05 8.907478792252732e-05 8.907479035258348e-06
400 training losses:  0.00029236680711619556 9.431187703512478e-05 9.431187652353401e-05 9.43118758982564e-05 9.431188004782598e-06
400 training losses:  0.0002927224850282073 9.442661001912711e-05 9.442660731906471e-05 9.44266069780042e-05 9.44266087188339e-06
400 training losses:  0.00030466311727650464 9.827841518017522e-05 9.827841526544034e-05 9.827841731180342e-05 9.82784176173368e-06
400 training losses:  0.00028348478372208774 9.144669019178764e-05 9.144668996441396e-05 9.144669331817568e-05 9.144669320448884e-06
400 training losses:  0.0002757420006673783 8.894905136003217e-05 8.894904829048755e-05 8.894905374745576e-05 8.894905327849756e-06
400 training losses:  0.00027620140463113785 8.909721827876638e-05 8.909721606187304e-05 8.909721856298347e-05 8.909721891825484e-06
400 training losses:  0.00028474084683693945 9.185189446725417e-05 9.185189523464032e-05 9.18518951777969e-05 9.18518980341787e-06
400 training losses:  0.0002732486464083195 8.814471280516045e-05 8.814471260620849e-05 8.814471723894712e-05 8.814471531337631e-06
400 training losses:  0.0002732760040089488 8.815353709223928e-05 8.815353527324987e-05 8.815353771751688e-05 8.815353844227047e-06
400 training losses:  0.00027821207186207175 8.974581160714479e-05 8.974581484721966e-05 8.974581430720718e-05 8.974581568566009e-06
400 training losses:  0.00028769593336619437 9.280513347675878e-05 9.280513273779434e-05 9.280513498310938e-05 9.280513577181182e-06
400 training losses:  0.00028144128737039864 9.078752697178061e-05 9.078752628965958e-05 9.078752862023975e-05 9.078752874813745e-06
400 training losses:  0.0002917477977462113 9.411218849209035e-05 9.411218718469172e-05 9.411218826471668e-05 9.411218840682523e-06
400 valid losses:  0.00027066075585935323 8.730992213656918e-05 8.730992061600773e-05 8.730992000494098e-05 8.730992243854985e-06
400 training loss:  0.0002917477977462113 valid loss:  0.00027066075585935323 training acc:  63.072311046511636 %   valid accuracy:  50.49881894364316 %
450 training losses:  0.00026677746791392565 8.60572281453642e-05 8.605722553056694e-05 8.605722609900113e-05 8.605722797483395e-06
450 training losses:  0.0002835257619153708 9.145992930825741e-05 9.145993186621126e-05 9.145992680714699e-05 9.145993139725306e-06
450 training losses:  0.0002927777240984142 9.444441027994799e-05 9.444441039363483e-05 9.444440897254935e-05 9.444441204209397e-06
450 training losses:  0.00027948926435783505 9.015783541599376e-05 9.015783450649906e-05 9.015783734867e-05 9.015783611232564e-06
450 training losses:  0.00026997766690328717 8.708957295766595e-05 8.708956988812133e-05 8.708957176395415e-05 8.708957430769715e-06
450 training losses:  0.00027865596348419785 8.98890232008398e-05 8.988902328610493e-05 8.988902405349108e-05 8.98890237976957e-06
450 training losses:  0.000268704432528466 8.66788496978188e-05 8.667884810620308e-05 8.667884659985248e-05 8.66788514386485e-06
450 training losses:  0.0002864331181626767 9.239777364200563e-05 9.239777216407674e-05 9.239777085667811e-05 9.239777568836871e-06
450 training losses:  0.00028087591635994613 9.06051463402946e-05 9.060513929171066e-05 9.060514355496707e-05 9.06051448623657e-06
450 training losses:  0.0003013242094311863 9.7201350541809e-05 9.720134923441037e-05 9.720135133761687e-05 9.720135359714277e-06
450 training losses:  0.0002942823339253664 9.49297834722529e-05 9.492978503544691e-05 9.492978162484178e-05 9.492978584546563e-06
450 training losses:  0.0002724039659369737 8.787224106754365e-05 8.787224101070024e-05 8.787224135176075e-05 8.787224217599032e-06
450 training losses:  0.00026088845334015787 8.415756548174613e-05 8.415755871737929e-05 8.41575632648528e-05 8.415756340696134e-06
450 training losses:  0.0002762840304058045 8.912387474424577e-05 8.91238745452938e-05 8.912387463055893e-05 8.912387764681284e-06
450 training losses:  0.0002664006024133414 8.593568358605808e-05 8.593568293235876e-05 8.593568549031261e-05 8.593568459502876e-06
450 training losses:  0.00028651722823269665 9.242492365046928e-05 9.24249255263021e-05 9.242492046723783e-05 9.24249241762709e-06
450 training losses:  0.00027305076946504414 8.808087551415156e-05 8.808087977740797e-05 8.808087909528695e-05 8.808087947898002e-06
450 training losses:  0.00028089870465919375 9.06124838593314e-05 9.061248024977431e-05 9.061248380248799e-05 9.061248380959341e-06
450 training losses:  0.0002855239436030388 9.210449564989176e-05 9.210449812258048e-05 9.210449690044697e-05 9.210449746888116e-06
450 training losses:  0.0002737541508395225 8.830778921264937e-05 8.830779461277416e-05 8.830779182744664e-05 8.830779272273048e-06
450 training losses:  0.0002729817933868617 8.805865815020297e-05 8.805865729755169e-05 8.805865803651614e-05 8.805865952865588e-06
450 training losses:  0.00029018273926340044 9.360731465335448e-05 9.360731581864457e-05 9.360731360175123e-05 9.360731683116796e-06
450 training losses:  0.0002982683072332293 9.6215562862767e-05 9.621555996375264e-05 9.621556506544948e-05 9.621556394279196e-06
450 training losses:  0.0002720695047173649 8.776435589652465e-05 8.776435731761012e-05 8.776435947766004e-05 8.776436096979978e-06
450 training losses:  0.00027945704641751945 9.014743829993677e-05 9.014743591251317e-05 9.014744114210771e-05 9.014743987734164e-06
450 training losses:  0.0002790229918900877 9.000740743658753e-05 9.000740695341847e-05 9.000740817555197e-05 9.00074077136992e-06
450 training losses:  0.0002733408473432064 8.817446558850861e-05 8.817446348530211e-05 8.817446544640006e-05 8.81744655600869e-06
450 training losses:  0.00027980117010883987 9.025843525023447e-05 9.025843604604233e-05 9.025843621657259e-05 9.025843716869986e-06
450 training losses:  0.00028076680609956384 9.056992752221049e-05 9.056992439582245e-05 9.05699248505698e-05 9.056992709588485e-06
450 training losses:  0.0002887113660108298 9.313269686117565e-05 9.313269373478761e-05 9.313269632116317e-05 9.313269830002469e-06
450 training losses:  0.0002907172020059079 9.377973984214805e-05 9.377974106428155e-05 9.377974771496156e-05 9.377974347302143e-06
450 training losses:  0.0002697846502996981 8.702730366394462e-05 8.702730326604069e-05 8.702730252707624e-05 8.702730504239753e-06
450 training losses:  0.0002876341750379652 9.278521679334517e-05 9.278521548594654e-05 9.278521577016363e-05 9.278521677202889e-06
450 training losses:  0.00028498045867308974 9.192917283940005e-05 9.192917275413492e-05 9.192917107725407e-05 9.192917648448429e-06
450 training losses:  0.0002919552498497069 9.417910419529107e-05 9.417910715114886e-05 9.417910661113638e-05 9.417910730391554e-06
450 training losses:  0.000270788004854694 8.73509735015432e-05 8.735097645740098e-05 8.735097344469978e-05 8.735097537737602e-06
450 training losses:  0.0002839528606273234 9.159769115285599e-05 9.15976863780088e-05 9.159768899280607e-05 9.159769021493958e-06
450 training losses:  0.0002716078597586602 8.761544501112439e-05 8.76154444426902e-05 8.761544478375072e-05 8.761544510349495e-06
450 training losses:  0.00030532432720065117 9.849171482301244e-05 9.849171975417903e-05 9.84917205784086e-05 9.849172164067e-06
450 training losses:  0.0002983660961035639 9.624712896538767e-05 9.624712831168836e-05 9.624713408129537e-05 9.624713271705332e-06
450 training losses:  0.00028496221057139337 9.192330634277823e-05 9.192330355745071e-05 9.192330531959669e-05 9.192330558960293e-06
450 training losses:  0.0002844639529939741 9.176255809961731e-05 9.176255275633594e-05 9.176255196052807e-05 9.176255673537526e-06
450 training losses:  0.00027318482170812786 8.812414986891781e-05 8.812414958470072e-05 8.812414958470072e-05 8.812415266845619e-06
450 valid losses:  0.00027182687902893576 8.768608960707525e-05 8.768608995524119e-05 8.768609044551567e-05 8.768609202292055e-06
450 training loss:  0.00027318482170812786 valid loss:  0.00027182687902893576 training acc:  68.99330789728684 %   valid accuracy:  56.295698116987175 %